{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df4b6c83-525e-496c-abd1-710c51c365be",
   "metadata": {},
   "source": [
    "# Multi-objective Fitting and Parameter Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "107ea813-0ac9-45a0-ac90-9cbf1acda080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING LIBRARIES\n",
    "import os\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import io as sio\n",
    "import glob\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import distance_FC\n",
    "from distance_FC import distance_FC\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# IMPORT THE EMPIRICAL DATA FROM THE ASD SUBJECT (RESTING STATE EEG) and the simulation data\n",
    "#rest = np.load(r\"C:\\Users\\leona\\Leo_Python\\rest_asd.npy\")\n",
    "rest = np.load(\"/home/l_martinelli/Michelangelo/FITTING/rest_asd.npy\")\n",
    "n_channels = rest.shape[0]\n",
    "rest.shape\n",
    "#file_names = glob.glob(\"/home/l_martinelli/Michelangelo/subResults/mat_eeg/*.mat\")  #extract a list of file names in the directory\n",
    "file_names = glob.glob(\"/home/l_martinelli/Michelangelo/Parameter_fitting_2024-08-28/Results/RUN03-BestFC_Point_Linear_Scale_PSD_Optimization_vaying_AaBb/*.mat\")  #extract a list of file names in the directory\n",
    "n_trials = len(file_names)   # number of simulation trials \n",
    "a = str(file_names[0])  #load one data to extract the information about n_points\n",
    "sim_surface = sio.loadmat(a)\n",
    "simm = np.array(sim_surface['eeg'])\n",
    "n_points = int(simm.shape[0])  #assuming the shapes of simulations is [n_points, n_channels]\n",
    "n_ch = 64  \n",
    "simulation = np.zeros([n_points, n_ch, n_trials])  # array to be filled with simulation in the shape [number of points, number of channels, number of trials]\n",
    "sim = np.zeros([n_channels, n_points, n_trials])  # array with the mask [number of channels (in common with empirical data), number of points, number of trials]\n",
    "for i in range (n_trials):\n",
    "    a = str(file_names[i])\n",
    "    sim_surface = sio.loadmat(a)\n",
    "    simulation[:,:,i] = np.array(sim_surface['eeg'])\n",
    "    sim_m = simulation[:,:,i].mean(axis=1)\n",
    "    for j in range (n_ch):\n",
    "        simulation[:,j,i] = simulation[:,j,i] - sim_m\n",
    "        \n",
    "# MASK FOR THE EXTRACTION OF THE 16 CHANNELS IN COMMON WITH THE EMPIRICAL DATA\n",
    "#mask_old = (4,12,20,26,14,22,32,37,47,30,33,39,49,57,63,51)\n",
    "mask = (42,21,2,9,36,33,10,16,0,3,45,49,28,61,8,35)\n",
    "for i in range (n_channels):\n",
    "    sim[i,:,:] = simulation[:,mask[i],:]\n",
    "\n",
    "# DELETE FIRST 500 POINTS\n",
    "\n",
    "sim = sim[:,500:,:]\n",
    "sim.shape\n",
    "\n",
    "#compute and return the pearson correlation matrix for the empirical data (in shape [n_channels,n_channels]) or simulated [n_channels,n_channels,n_trials] \n",
    "#and the array of the triangular part of the matrix \n",
    "# data are supposed to be in the shape [n_channels, n_points, n_trials]\n",
    "\n",
    "def pearson_connectivity(data):\n",
    "    data_shape = data.shape\n",
    "    n_channels = data_shape[0]\n",
    "    n_array = int((n_channels)*(n_channels - 1)/2)\n",
    "    n_trials = data_shape[-1]\n",
    "    n_points = data_shape[1]\n",
    "    #distinguish the case between one trial and many trials (simulations)\n",
    "    if n_trials == n_points:\n",
    "        functional_matrix = np.zeros([n_channels,n_channels])\n",
    "        functional_array = np.zeros([n_array])\n",
    "        pearson_correlation = pd.DataFrame(data=data[:, :]).T.corr()\n",
    "        functional_matrix = pearson_correlation.to_numpy()\n",
    "        #extract the triangular part\n",
    "        z = -1\n",
    "        for i in range (1,n_channels):\n",
    "            for j in range (0,i):\n",
    "                z = z + 1 \n",
    "                functional_array[z] = functional_matrix[i,j]\n",
    "    else:\n",
    "        functional_matrix = np.zeros([n_channels,n_channels,n_trials])\n",
    "        functional_array = np.zeros([n_array,n_trials])\n",
    "        for i in range (n_trials):\n",
    "            pearson_correlation = pd.DataFrame(data=data[:, :, i]).T.corr()\n",
    "            functional_matrix[:,:,i] = pearson_correlation.to_numpy()\n",
    "            z = -1\n",
    "            for j in range (1,n_channels):\n",
    "                for k in range (0,j):\n",
    "                    z = z + 1\n",
    "                    functional_array[z,i] = functional_matrix[j,k,i]\n",
    "    return functional_matrix, functional_array\n",
    "        \n",
    "\n",
    "\n",
    "#compute and return the correlation between the functional connectivity matrices: simulated vs recorded for each simulation trial\n",
    "\n",
    "def fit_connectivity(simulation):\n",
    "    simulated_connectivity = pearson_connectivity(simulation)[1]\n",
    "    recorded_connectivity = pearson_connectivity(rest)[1]\n",
    "    simulation_shape = simulation.shape\n",
    "    n_channels = simulation_shape[0]\n",
    "    n_array = int((n_channels)*(n_channels - 1)/2)\n",
    "    n_points = simulation_shape[1]\n",
    "    n_trials = simulation_shape[-1]\n",
    "    D = np.zeros([n_array,2])  # contains two vectors: the simulated and the empirical data to be compared\n",
    "    if n_trials == n_points:\n",
    "        correlation_fit = np.zeros([1])\n",
    "        B = np.asarray(simulated_connectivity[:]).reshape(-1)\n",
    "        C = np.asarray(recorded_connectivity[:]).reshape(-1)\n",
    "        D[:,0] = B\n",
    "        D[:,1] = C\n",
    "        diff_corr_ = pd.DataFrame(data=D[:, :]).corr()\n",
    "        diff_corr_ = diff_corr_.to_numpy()\n",
    "        correlation_fit = diff_corr_[0,1]\n",
    "    else:\n",
    "        correlation_fit = np.zeros([n_trials])\n",
    "        for i in range (n_trials):\n",
    "            B = np.asarray(simulated_connectivity[:,i]).reshape(-1)\n",
    "            C = np.asarray(recorded_connectivity[:]).reshape(-1)\n",
    "            D[:,0] = B\n",
    "            D[:,1] = C\n",
    "            diff_corr_ = pd.DataFrame(data=D[:, :]).corr()\n",
    "            diff_corr_ = diff_corr_.to_numpy()\n",
    "            correlation_fit[i] = diff_corr_[0,1]\n",
    "    return correlation_fit\n",
    "\n",
    "#fit for the uploaded simulations 'sim'\n",
    "fit0 = fit_connectivity(sim)\n",
    "fit0_ = fit0[~np.isnan(fit0)]\n",
    "max0 = fit0_.max()\n",
    "best0 = np.where(fit0 == max0)\n",
    "best0 = np.array(best0)\n",
    "\n",
    "\n",
    "#COMPUTE DISTANCE BETWEEN FC MATRICES WITH THE GEODESIC DISTANCE\n",
    "def fit_geodesic(simulation):\n",
    "    FC1 = pearson_connectivity(rest)[0]\n",
    "    d_geodesic = np.zeros([n_trials])\n",
    "    for i in range(n_trials):\n",
    "        if fit0[i] > 0:    #discard null simulations\n",
    "            FC2 = pearson_connectivity(simulation[:,:,i])[0]\n",
    "            dist = distance_FC(FC1, FC2)\n",
    "            d_geodesic[i] = dist.geodesic()\n",
    "    return d_geodesic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c296cfd-f8f7-444b-ba04-b801257d7124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the PSD of the data and the extract periodic and aperiodic compents with FOOOF algorithm\n",
    "#compute PSD with Welch's method via median average, the signal must be in the form [n_channels,n_points]\n",
    "\n",
    "def PSD(data):\n",
    "    \n",
    "    n_channels = data.shape[0]\n",
    "    fs = 256\n",
    "    f, spec = signal.welch(data[0,:],fs = fs,nperseg = 1024)\n",
    "    f_nyq = spec.shape[0]\n",
    "    spectrum = np.zeros([f_nyq ,n_channels])\n",
    "    for i in range (n_channels):\n",
    "        f, spectrum[:,i] = signal.welch(data[i,:],fs = fs, average = 'median',nperseg = 1024)\n",
    "\n",
    "    spectrum = spectrum[:160,:]\n",
    "    f = f[:160]\n",
    "    spectrum_mean = spectrum.mean(axis = 1)\n",
    "    spectrum_max = spectrum_mean.max()\n",
    "    spectrum_norm = spectrum_mean/spectrum_max\n",
    "\n",
    "    return spectrum_norm\n",
    "\n",
    "\n",
    "def fit_psd(simulation):\n",
    "    n_trials = simulation.shape[2]\n",
    "    sim_psd = np.zeros([160,n_trials])\n",
    "    mse_psd = np.zeros([n_trials]) \n",
    "    rec_psd = PSD(rest)  #compute psd and aperiodic exponent of empirical data\n",
    "    for j in range(n_trials):\n",
    "        sim_psd[:,j] = PSD(simulation[:,:,j]) #compute psd and aperiodic exponent of simulated data\n",
    "        if sim_psd[0,j] > 0 :\n",
    "            mse_psd[j] = mean_squared_error(sim_psd[:,j], rec_psd)\n",
    "    return mse_psd, sim_psd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83633e75-e976-4618-a93c-362c9762978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the multi-objective fit and the corresponding simulation labels\n",
    "\n",
    "fit0 = fit_connectivity(sim)\n",
    "fit0_ = fit0[~np.isnan(fit0)]\n",
    "max0 = fit0_.max()\n",
    "best0 = np.where(fit0 == max0)\n",
    "best0 = np.array(best0)\n",
    "\n",
    "fit1, psd1 = fit_psd(sim)\n",
    "fit1_ = fit1[~np.isnan(fit1)]\n",
    "max1 = fit1_.max()\n",
    "best1 = np.where(fit1 == max1)\n",
    "best1 = np.array(best1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7166e73-a023-4073-939d-33dacdcfc852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSD_COMPONENTS(psd):\n",
    "    fs = 256\n",
    "    f, spec = signal.welch(rest[0,:],fs = fs, nperseg = 512)\n",
    "    f = f[:80]\n",
    "    alpha = np.zeros([5075])\n",
    "    peak = np.zeros([5075])\n",
    "    n_p = np.zeros([5075])\n",
    "    for i in range (5075):\n",
    "         if psd[0,i] > 0:\n",
    "            # Initialize FOOOF object\n",
    "            fm = FOOOF()#aperiodic_mode='knee')\n",
    "            # Define frequency range across which to model the spectrum\n",
    "            freq_range = [1, 40]\n",
    "            # Model the power spectrum with FOOOF, and print out a report\n",
    "            #fm.report(f, spectrum_norm, freq_range)\n",
    "            fm.fit(f, psd[:,i], freq_range)\n",
    "            #extract aperiodic component\n",
    "            alpha[i] = fm.aperiodic_params_[1]\n",
    "            #and periodic component (first peak in the PSD)\n",
    "            p = fm.peak_params_\n",
    "            n_p[i] = fm.n_peaks_\n",
    "            if n_p[i] > 0:\n",
    "                peak[i] = p[0,0]\n",
    "    return peak, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86db6c1-a667-4adf-8e69-bf11df462648",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETER IMPORTANCE\n",
    "#ONCE A SIMULATION GRID SEARCH IS RUNNED FITTING VALUES TOGETHER WITH PARAMETERS ARRAYS \n",
    "#ARE USED FOR PARAMETR IMPORTANCE ON BOTH THE FITTING RESULTS AND ON FEATURES OF THE WHOLE BRAIN ACTIVITY\n",
    "\n",
    "#parameters argument. these depend on the particular grid search implemented\n",
    "arg = ['jrm.a',\n",
    " 'jrm.b',\n",
    " 'white_matter_speed',\n",
    " 'local_connectivity_sigma',\n",
    " 'local_coupling_strength',\n",
    " 'jrm.mu',\n",
    " 'white_matter_coupling.a']\n",
    "\n",
    "#train a random forest on the data and compute parameter gini importance\n",
    "\n",
    "X = pd.DataFrame(par.T, columns = arg)     #par is the array of parameters  with parameters arguments in 'arg' list, result of the grid search simulation\n",
    "y1 = alpha\n",
    "y2 = peak\n",
    "y3 = fit0\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.25)  #use y1 for periodic peak, y2 for aperiodic exponent or y3 for FC fit\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "X_train_random = X_train.copy()\n",
    "X_train_random[\"RANDOM\"] = np.random.RandomState(42).randn(X_train.shape[0])\n",
    "rf_random = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_random.fit(X_train_random, y_train)\n",
    "global_importances_random = pd.Series(rf_random.feature_importances_, index=X_train_random.columns)\n",
    "\n",
    "#validate computing permutation importance\n",
    "result = permutation_importance(\n",
    "    rf, X_train, y_train, n_repeats=10, random_state=42, n_jobs=2\n",
    ")\n",
    "\n",
    "sorted_importances_idx = result.importances_mean.argsort()\n",
    "importances = pd.DataFrame(\n",
    "    result.importances[sorted_importances_idx].T,\n",
    "    columns=X.columns[sorted_importances_idx],\n",
    ")\n",
    "ax = importances.plot.box(vert=False, whis=10)\n",
    "\n",
    "#extend analysis considering shapley values\n",
    "xplainer = shap.TreeExplainer(rf)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n",
    "shap.summary_plot(shap_values, X_test, title = \"Shapley value feature importances on periodic peak\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
